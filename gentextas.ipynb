{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gentextas.ipynb",
      "provenance": [],
      "mount_file_id": "1K_JDjSYx0eqo3hu0X6GnlW6SMPO5T_Is",
      "authorship_tag": "ABX9TyMP7ie5IQHhF2DlyjDb4xm+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hokkebu/test/blob/main/gentextas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "imput.txtに学習させたいテキストをコピペして使う。"
      ],
      "metadata": {
        "id": "s4I0RqeenyZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル実装\n",
        "\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Activation, LSTM\n",
        "#from keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "# from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        "# データ取得\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/10_BD/Nichiren/IbunBunseki/input.txt\"\n",
        "bindata = open(path, \"rb\").read()\n",
        "text = bindata.decode(\"utf-8\")\n",
        "\n",
        "print(\"Size of text: \",len(text)) # テキスト中の単語と句読点（トークン）の合計数を求める\n",
        "chars = sorted(list(set(text))) # 文字の種類（set(text)）をリスト化してソート（記号、あいうえお順）する\n",
        "print(\"Total chars :\",len(chars))\n",
        "\n",
        "\n",
        "# 40文字の次の1文字を学習させる. 3文字ずつずらして40文字と1文字というセットを作る\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text)-maxlen, step): \n",
        "  #3文字ずつずらした40文字text[i:i+maxlenのリスト\n",
        "  sentences.append(text[i:i+maxlen]) \n",
        "  #40文字の次の1文字text[i+maxlen]のリスト\n",
        "  next_chars.append(text[i+maxlen]) \n",
        "print(\"size of sentences : \", len(sentences))\n",
        "print(\"size of next_chars : \", len(next_chars))\n",
        "\n",
        "\n",
        "#辞書を作成する\n",
        "char_indices = dict((c,i) for i,c in enumerate(chars)) #keyが文字で、valueが番号\n",
        "indices_char = dict((i,c) for i,c in enumerate(chars)) #keyが番号で、valueが文字\n",
        "\n",
        "\n",
        "# テキストのベクトル化\n",
        "# 配列の全要素をFalseで初期化\n",
        "X = np.zeros((len(sentences),maxlen,len(chars)),dtype=np.bool)\n",
        "y = np.zeros((len(sentences),len(chars)),dtype=np.bool)\n",
        "\n",
        "# 番号と40文字リストのループ\n",
        "for i, sentence in enumerate(sentences): \n",
        "  # 番号と40文字の各文字のループ\n",
        "  for t ,char in enumerate(sentence): \n",
        "    X[i,t,char_indices[char]] = 1 # char_indices[char] = 文字に該当する辞書char_indicesの番号\n",
        "  y[i,char_indices[next_chars[i]]] = 1 # 次の1文字に該当する辞書char_indicesの番号\n",
        "\n",
        "\n",
        "# LSTMを使ったモデル作成\n",
        "model = Sequential() \n",
        "model.add(LSTM(128, input_shape=(maxlen,len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation(\"softmax\"))\n",
        "optimizer = RMSprop(lr = 0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer)\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "  # numpyで用いられるarray形式に変換\n",
        "  preds = np.asarray(preds).astype(\"float64\") \n",
        "\n",
        "  # 1 / temperature * log(preds) を計算  log(preds ** (1 / temperature)) \n",
        "  # temperatureは平滑化のための係数で、値が大きいほど、確率分布が平になる (つまり言語モデルによる確率分布が重要視されなくなる)\n",
        "  preds = np.log(preds) / temperature       \n",
        "\n",
        "  # exp_preds = preds ** (1 / temperature)を計算　expを取るのは確率の定義である値が0以上であるようにするため\n",
        "  exp_preds = np.exp(preds)   \n",
        "\n",
        "  # predsを確率分布として計算\n",
        "  preds = exp_preds / np.sum(exp_preds)       \n",
        "\n",
        "  # predsに従って文字を一つサンプリング　probsはサンプリングされた文字インデックスのみ1、それ以外は0となるarrayとなる\n",
        "  probs = np.random.multinomial(1, preds, 1)   \n",
        "\n",
        "  # argmaxを取ることによって、サンプリングされた文字インデックス\n",
        "  return np.argmax(probs)                      \n",
        "\n",
        "\n",
        "\n",
        "# モデルの学習\n",
        "num = 30\n",
        "for iteration in range(1,num):\n",
        "  print(\"-\"*50)\n",
        "  print(\"繰り返し回数: \",iteration)\n",
        "\n",
        "  # モデルの学習\n",
        "  history = model.fit(X, y, batch_size=128, epochs=1)\n",
        "  loss = history.history[\"loss\"]\n",
        "\n",
        "  # グラフ表示\n",
        "  plt.plot(iteration,  loss, \"bo\", label = \"Training loss\" )\n",
        "\n",
        "  # テキストの何文字目から取得するかをランダムに選択\n",
        "  # start_index = random.randint(0, len(text)-maxlen-1)\n",
        "  # 生成文のスタート\n",
        "  ## start_index = 241 # 241は本文のスタート部分\n",
        "  start_index = 0\n",
        "\n",
        "\n",
        "# 予測\n",
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print()\n",
        "    print(\"-----diversity\", diversity)\n",
        "\n",
        "    generated =\"\"\n",
        "\n",
        "    # 40文字の文章\n",
        "    sentence = text[start_index: start_index + maxlen ]\n",
        "    generated += sentence\n",
        "    print(\"-----Seedを生成しました: \")\n",
        "    print(sentence)\n",
        "    \n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    # 40文字のあとの、次の400文字を予測\n",
        "    for i in range(400):\n",
        "\n",
        "      # sentenceのベクトル化\n",
        "      x = np.zeros((1,maxlen,len(chars)))\n",
        "      for t,char in enumerate(sentence):\n",
        "          x[0, t, char_indices[char]] = 1\n",
        "\n",
        "      # 次の文字を予測\n",
        "      preds = model.predict(x, verbose =9)[0]\n",
        "      # 次の1文字のインデックス\n",
        "      next_index = sample(preds, diversity)\n",
        "      # 次の1文字\n",
        "      next_char = indices_char[next_index]\n",
        "      # 次の1文字を追加する\n",
        "      generated += next_char\n",
        "\n",
        "      # 2文字目からに、次の1文字を追加した40字（1文字ずらした40字）\n",
        "      sentence = sentence[1:] + next_char\n",
        "      \n",
        "      # 次の1文字をコンソールに出力\n",
        "      sys.stdout.write(next_char)\n",
        "      sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "model.save('souseki_model.h5')\n",
        "file = open('sousekigentext.txt','w+',encoding='utf-8').write(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ClAKBqEId1JU",
        "outputId": "27a10af8-9e82-490a-e047-abd080d11477"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1文字以上Hokke.png\t\t NSI_cleaned_noTitle.txt\n",
            " 2文字以上Hokke.png\t\t'NSI_cleaned_noTitle.txt のコピー'\n",
            " HokkeWordsList1charOver.txt\t NSI_cleaned.txt\n",
            " HokkeWordsListOver2chars.txt\t NSI_cleaned_withTitleNoDankan.txt\n",
            " input.txt\t\t\t NSI_cleaned_withTitle.txt\n",
            " keras_lstm.py\t\t\t NSI_nonQTnonRB.txt\n",
            " loss.png\t\t\t NSI_nonQTnonRB_WordsRank.txt\n",
            " mini.gdoc\t\t\t output_20200509_104934.log\n",
            " NichirenShimpitsuIbun.txt\t over3mojiWordRank.txt\n",
            " NotRankWords.txt\t\t test.py\n",
            " NSI_1_ページ表記なし.txt\t wordcloud2.png\n",
            " NSI_2_ページ表記なし.txt\t wordcloud.png\n",
            " NSI_cleaned_noTitle_mini.gdoc\t wordcloud_test.py\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Size of text:  10235\n",
            "Total chars : 703\n",
            "size of sentences :  3399\n",
            "size of next_chars :  3399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "繰り返し回数:  1\n",
            "27/27 [==============================] - 2s 14ms/step - loss: 5.1513\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  2\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 4.6679\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  3\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 4.1774\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  4\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 3.7287\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  5\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 3.3031\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  6\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2.9233\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  7\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2.5885\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  8\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 2.1948\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  9\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1.8761\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1.5165\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  11\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 1.2217\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  12\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.9564\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  13\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.7150\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  14\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5603\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  15\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4211\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  16\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.3322\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  17\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2473\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  18\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2014\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  19\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.1630\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  20\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.1485\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  21\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.1191\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  22\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.1090\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  23\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0915\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  24\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.1015\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  25\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0857\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  26\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0698\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  27\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0780\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  28\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0661\n",
            "--------------------------------------------------\n",
            "繰り返し回数:  29\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0669\n",
            "\n",
            "-----diversity 0.2\n",
            "-----Seedを生成しました: \n",
            "人生の長い経験をお持ちの池田先生から思うぞんぶん、私たちにかたっていただきたいと\n",
            "人生の長い経験をお持ちの池田先生から思うぞんぶん、私たちにかたっていただきたいと思うわかった\n",
            "　「おしがありもあるがら、何かもしてもい。しかし、そのですべての人は二と」\n",
            "　池田　親に自分の道にきるわかもいない。\n",
            "　ことは、あせさせ、自分を顕うい。\n",
            "　――　「今い人の指にないる。\n",
            "　人生き、何かも評はんし、自分の道にするとんない人に、ることを、そういうゆが「自分はことだん。自分がやっている人生きます。\n",
            "　人生き尊るとんだ自分に自分を顕くきた。\n",
            "　――　あり太対にないうから、何かもから「何ですべての人はな」」\n",
            "　池田　親にあるされ、自分の使陽をうる世もしい、にきない。自分がやっている人生きまれているから、何かもあるもは、自分はやくのための世とを私は大にな世界には私るされでもらいた。。今生苦してい私は、学ぶんといくのです。自分が道にいる親がいる。「自分があない人が勝る。学んないなのことを私ているもら、がい。君と、そのです。愚わかるもして、ます。どのかせ、ことやりない」とめて\n",
            "\n",
            "-----diversity 0.5\n",
            "-----Seedを生成しました: \n",
            "人生の長い経験をお持ちの池田先生から思うぞんぶん、私たちにかたっていただきたいと\n",
            "人生の長い経験をお持ちの池田先生から思うぞんぶん、私たちにかたっていただきたいと思うわかったも、何でも勝るかも、それぞ言のは、片間のことを私る世です。\n",
            "　どんな悩があっても、人も、苦しみながなく、人もっては、うな世界をは、あらもってもらいたい。親ががあっても、「目して一生き方。\n",
            "　こかで、自分の道にするとも、いるかど、それもいくの生き二何です。その人の中は、自分をことをうってもらいたい。親ががあっても、「目しては、人生活れない」といて、人格は扱」\n",
            "　たどかか、自分があきます。それぞ言の指導者の道に大太になってもらいない。君と言うの。きてやり苦して、人格のたす。そんない人があることは、うな世も、あながら、あり「何をもある。しても、人生が勝太は自分のことを足足るししたい。\n",
            "　――　あるかど、自分の道に大きな」ないう。苦しては、う。世界的は、あなられも、あり方々をている。も母んない。しかも、どのですかも、自分は自分は、学校のあり二えることがあっても、「目を上のもことです。自\n",
            "\n",
            "-----diversity 1.0\n",
            "-----Seedを生成しました: \n",
            "人生の長い経験をお持ちの池田先生から思うぞんぶん、私たちにかたっていただきたいと\n",
            "人生の長い経験をお持ちの池田先生から思うぞんぶん、私たちにかたっていただきたいと思う後ははた」と思うのことががきるこ。、何りやの輝度ち外んない。自分が強、あるから、何はやり界てはあな」とがあるがあるが\n",
            "　私して、長かつは、大学やになえない」とがわからこれが言わした。\n",
            "　青にはわ大\n",
            "　に大にかなのどうかだ、自分が道にす。\n",
            "　まる著言言わは、自分自身のしをってはてくされた。親の生きべてい人かも、自分は、あき人もいるのですかも、自分があり太い。自分を豊の使量もあきない。自分はや評指」と重きに語ることは、くつ世界的ないなけならないが何です。\n",
            "　どんな悩であっても、親は歩みない。自分が強くの気げがいう」といねの人かもっている。\n",
            "　十ししかわかも、何かもってもらいたか。父とですべての、かも前へ進もいる。\n",
            "　――　あるから、何か校とは、うい世界どとだう人があると思、まった何かないるただ、「悔しお母さんのことを私て病るもしれたい。\n",
            "　した言があって、も、今の人も二枚です。\n",
            "　どかして\n",
            "\n",
            "-----diversity 1.2\n",
            "-----Seedを生成しました: \n",
            "人生の長い経験をお持ちの池田先生から思うぞんぶん、私たちにかたっていただきたいと\n",
            "人生の長い経験をお持ちの池田先生から思うぞんぶん、私たちにかたっていただきたいと思うわかったし、勝分は毎く、少ももっためした\n",
            "　目だかのあきたりないなけがないの人がわちのわかでもしてい苦し、いうの諸、、くの大うのです。諸わそう人すか愚しれが立す。「個つの字そう「人が生きないがあっているそどすよどしかく、自分のあきききない。自分できないるから、はやじさと、うべての世界とは私自分ら行くきる。\n",
            "　そして使私は、前のリも広本後はないのに個だかです。その人ことは、自分を体くってく足う」という決くる親は、何ですべをうちもんでほしい人間とは、」大な棄言の大きな世」の悔をある。\n",
            "　せるかだ、今の人間という」生九」とお外に―る。今の繰苦していがあってもらいた。成だ友がいうらです。\n",
            "　こと言うとは、それな若のはならないなから、何をたう」てくない。もった。だかたん、お母とんともきないよかだろ、自分の使子あるま学ないんだだかが、強しさ進、「あといかか足\n",
            "　人たちが、「快んの生とを何っているの\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}